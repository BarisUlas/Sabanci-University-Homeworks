{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML-HW1-GermanCreditCard.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTfDIhAYYjaX",
        "colab_type": "text"
      },
      "source": [
        "# Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGi6c-0uZSeB",
        "colab_type": "code",
        "outputId": "2f3d9a55-5b4c-49e8-fbb6-4099b662833b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFpeyxi8aqIl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# You can find the data under https://drive.google.com/drive/folders/1e550az93U3_kfRBbVY5PZnMKYwGYmHqi?usp=sharing\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from os.path import join\n",
        "\n",
        "path = \"/content/drive/My Drive/Colab Notebooks/cs412/Homeworks/hw1/\"\n",
        "\n",
        "train_data = pd.read_csv(join(path,\"train_data.csv\")) # One line of code\n",
        "train_label = pd.read_csv(join(path,\"train_label.csv\")) # One line of code\n",
        "\n",
        "test_data = pd.read_csv(join(path,\"test_data.csv\"))# One line of code\n",
        "test_label = pd.read_csv(join(path,\"test_label.csv\")) # One line of code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZXqzZlXBIN0",
        "colab_type": "code",
        "outputId": "36536af5-b916-4738-9fa9-ba6fae9fc26c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "# show random samples from the training data\n",
        "\n",
        "train_data.head() # One line of code"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>duration</th>\n",
              "      <th>credit_amount</th>\n",
              "      <th>installment_commitment</th>\n",
              "      <th>residence_since</th>\n",
              "      <th>age</th>\n",
              "      <th>existing_credits</th>\n",
              "      <th>num_dependents</th>\n",
              "      <th>f_worker</th>\n",
              "      <th>checking_status_&lt;0</th>\n",
              "      <th>checking_status_&gt;=200</th>\n",
              "      <th>checking_status_no checking</th>\n",
              "      <th>credit_history_critical/other existing credit</th>\n",
              "      <th>credit_history_delayed previously</th>\n",
              "      <th>credit_history_existing paid</th>\n",
              "      <th>credit_history_no credits/all paid</th>\n",
              "      <th>purpose_domestic appliance</th>\n",
              "      <th>purpose_education</th>\n",
              "      <th>purpose_furniture/equipment</th>\n",
              "      <th>purpose_new car</th>\n",
              "      <th>purpose_other</th>\n",
              "      <th>purpose_radio/tv</th>\n",
              "      <th>purpose_repairs</th>\n",
              "      <th>purpose_retraining</th>\n",
              "      <th>purpose_used car</th>\n",
              "      <th>savings_status_500&lt;=X&lt;1000</th>\n",
              "      <th>savings_status_&lt;100</th>\n",
              "      <th>savings_status_&gt;=1000</th>\n",
              "      <th>savings_status_no known savings</th>\n",
              "      <th>employment_4&lt;=X&lt;7</th>\n",
              "      <th>employment_&lt;1</th>\n",
              "      <th>employment_&gt;=7</th>\n",
              "      <th>employment_unemployed</th>\n",
              "      <th>personal_status_male div/sep</th>\n",
              "      <th>personal_status_male mar/wid</th>\n",
              "      <th>personal_status_male single</th>\n",
              "      <th>other_parties_guarantor</th>\n",
              "      <th>other_parties_none</th>\n",
              "      <th>property_magnitude_life insurance</th>\n",
              "      <th>property_magnitude_no known property</th>\n",
              "      <th>property_magnitude_real estate</th>\n",
              "      <th>other_payment_plans_none</th>\n",
              "      <th>other_payment_plans_stores</th>\n",
              "      <th>housing_own</th>\n",
              "      <th>housing_rent</th>\n",
              "      <th>job_skilled</th>\n",
              "      <th>job_unemp/unskilled non res</th>\n",
              "      <th>job_unskilled resident</th>\n",
              "      <th>own_telephone_yes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1169</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>67</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>48</td>\n",
              "      <td>5951</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>2096</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>49</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>42</td>\n",
              "      <td>7882</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>24</td>\n",
              "      <td>4870</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>53</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  duration  ...  job_unskilled resident  own_telephone_yes\n",
              "0   1         6  ...                       0                  1\n",
              "1   2        48  ...                       0                  0\n",
              "2   3        12  ...                       1                  0\n",
              "3   4        42  ...                       0                  0\n",
              "4   5        24  ...                       0                  0\n",
              "\n",
              "[5 rows x 49 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQIVU4-zXpE_",
        "colab_type": "text"
      },
      "source": [
        "# Train Decision Tree with default parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLznLl_lXYZf",
        "colab_type": "code",
        "outputId": "4e59c434-5652-4ac9-81ee-f8cd36c1046d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Train decision tree using the whole training data with **entropy** criteria\n",
        "\n",
        "clf = DecisionTreeClassifier(criterion='entropy', random_state = 44) # One line of code\n",
        "clf = clf.fit(train_data, train_label) # One line of code\n",
        "\n",
        "# Estimate the prediction of test data\n",
        "test_pred = clf.predict(test_data) # One line of code\n",
        "\n",
        "# Calculate accuracy of test data\n",
        "from sklearn.metrics import accuracy_score\n",
        "TestAcc = accuracy_score(test_label, test_pred)# One line of code\n",
        "print(\"Testing Accuracy = %.5f%%\" % (TestAcc * 100))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing Accuracy = 68.11594%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqgNZYUMXv8X",
        "colab_type": "text"
      },
      "source": [
        "# FineTune Decision Tree parameters\n",
        "\n",
        "1- Spliting dataset into train and validation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWJxk-zjy0Kv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split training data to 70% training and 30% validation\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_val, y_train, y_val = train_test_split(train_data, train_label, test_size=0.3) # One line of code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqws-kTZYHoG",
        "colab_type": "text"
      },
      "source": [
        "2- FineTune minimum sample split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1DvpmCCJXTb",
        "colab_type": "code",
        "outputId": "8d1941c3-4581-44a1-d08d-85fbb499afb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "min_samples_splits = range(2, 100)\n",
        "\n",
        "train_results = []\n",
        "val_results = []\n",
        "for min_samples_split in min_samples_splits:\n",
        "  \n",
        "  # Fit the tree using the 70% portion of the training data\n",
        "  dt = DecisionTreeClassifier(criterion='entropy',min_samples_split=min_samples_split, random_state = 44)  # One line of code\n",
        "  dt.fit(x_train, y_train)# One line of code\n",
        "  \n",
        "  # Evaluate on Training set\n",
        "  train_pred = dt.predict(x_train)  # One line of code\n",
        "  train_acc = accuracy_score(y_train, train_pred) # One line of code\n",
        "  train_results.append(train_acc)\n",
        "   \n",
        "  # Evaluate on Validation set\n",
        "  val_pred = dt.predict(x_val) # One line of code\n",
        "  val_acc = accuracy_score(y_val, val_pred) # One line of code\n",
        "  val_results.append(val_acc)\n",
        "  \n",
        "# Ploting\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(min_samples_splits, train_results, 'b')\n",
        "plt.plot(min_samples_splits, val_results,'r')\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akVAE3MbL7bE",
        "colab_type": "code",
        "outputId": "9d4dd815-5682-45d7-86bb-59211de6dfb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Choose the best minimum split sample based on the plot\n",
        "Best_minSampl = val_results.index(max(val_results)) + 2  # One line of code\n",
        "# Train decision tree using the full training data and the best minimum split sample\n",
        "clf = DecisionTreeClassifier(criterion='entropy', min_samples_split=Best_minSampl) # One line of code\n",
        "clf = clf.fit(train_data, train_label) # One line of code \n",
        "\n",
        "# Estimate the prediction of the test data\n",
        "test_pred = clf.predict(test_data) # One line of code\n",
        "\n",
        "# Calculate accuracy of test data\n",
        "TestAcc = accuracy_score(test_label, test_pred) # One line of code\n",
        "print(\"Testing Accuracy = %.5f%%\" % (TestAcc * 100))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing Accuracy = 71.98068%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VciE0lfYKhya",
        "colab_type": "text"
      },
      "source": [
        "# Now, apply the same procedure but using KNN instead of decision tree \n",
        "\n",
        "# For finetuning, find the best value of K to use with this dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdBaXNKoLBcL",
        "colab_type": "code",
        "outputId": "6d100151-1f19-4909-87d1-25716e39023e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# Write your code here\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# initialize the values of k to be a list of odd numbers between 1 and 30\n",
        "kVals = [i for i in range(1,30,2)]\n",
        "\n",
        "# Save the accuracies of each value of kVal in [accuracies] variable\n",
        "# hint: you can use accuracies.append(...) function inside the loop\n",
        "accuracies = []\n",
        "\n",
        "# loop over values of k for the k-Nearest Neighbor classifier\n",
        "for k in kVals:\n",
        "  # Follow what we did in decision tree part\n",
        "  model = KNeighborsClassifier(n_neighbors=k)\n",
        "  model.fit(x_train, y_train.values.reshape(-1))\n",
        "  \n",
        "  # Evaluate the model on validation set \n",
        "  score = model.score(x_val, y_val)\n",
        "  print(\"For k = %d, validation accuracy = %.5f%%\" % (k, score * 100))\n",
        "  \n",
        "  # Update the accuracies list\n",
        "  accuracies.append(score)\n",
        "\n",
        "\n",
        "\n",
        "# Train KNN using the full training data with the best K that you found\n",
        "best_k = kVals[accuracies.index(max(accuracies))]\n",
        "model = KNeighborsClassifier(n_neighbors=best_k)\n",
        "model.fit(train_data, train_label.values.reshape(-1))\n",
        "\n",
        "# Testing\n",
        "predictions = model.predict(test_data)\n",
        "TestAccuracy = accuracy_score(test_label, predictions)\n",
        "print(\"Testing Accuracy = %.5f%%\" % (TestAccuracy * 100))\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For k = 1, validation accuracy = 59.66387%\n",
            "For k = 3, validation accuracy = 60.92437%\n",
            "For k = 5, validation accuracy = 65.12605%\n",
            "For k = 7, validation accuracy = 66.80672%\n",
            "For k = 9, validation accuracy = 67.64706%\n",
            "For k = 11, validation accuracy = 68.90756%\n",
            "For k = 13, validation accuracy = 70.16807%\n",
            "For k = 15, validation accuracy = 71.00840%\n",
            "For k = 17, validation accuracy = 70.58824%\n",
            "For k = 19, validation accuracy = 71.42857%\n",
            "For k = 21, validation accuracy = 70.58824%\n",
            "For k = 23, validation accuracy = 72.26891%\n",
            "For k = 25, validation accuracy = 72.26891%\n",
            "For k = 27, validation accuracy = 73.52941%\n",
            "For k = 29, validation accuracy = 73.10924%\n",
            "Testing Accuracy = 70.53140%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMEdOIlJQBin",
        "colab_type": "text"
      },
      "source": [
        "# Bonus\n",
        "\n",
        "# Apply gridsearch using decision tree on any hyperparameter(s) of your choice, you have to beat your previous obtained accuracies to get the bonus\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-9TxVbXQCw7",
        "colab_type": "code",
        "outputId": "ae8c0c38-b3ce-41bb-e5a9-14389418a0bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Write your code here\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "model = DecisionTreeClassifier(criterion = 'entropy', random_state = 44)\n",
        "params = {'max_depth':range(2,10),'min_samples_split':range(2,50)}\n",
        "\n",
        "clf = GridSearchCV(model, params)\n",
        "clf.fit(train_data,train_label)\n",
        "est = clf.predict(test_data)\n",
        "TestAccuracy = accuracy_score(test_label, est)\n",
        "print('Best max_depth:', clf.best_estimator_.get_params()['max_depth'])\n",
        "print('Best min_samples_split:', clf.best_estimator_.get_params()['min_samples_split'])\n",
        "\n",
        "print(\"Testing Accuracy = %.5f%%\" % (TestAccuracy * 100))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best max_depth: 8\n",
            "Best min_samples_split: 43\n",
            "Testing Accuracy = 75.36232%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3VHrWpfyX6z",
        "colab_type": "code",
        "outputId": "3f850901-50da-4f5a-8a61-ee782e3162c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "report = classification_report(test_label, est)\n",
        "print(report)\n",
        "c_matrix = confusion_matrix(test_label,est)\n",
        "print(c_matrix)\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.37      0.47        62\n",
            "           1       0.77      0.92      0.84       145\n",
            "\n",
            "    accuracy                           0.75       207\n",
            "   macro avg       0.72      0.64      0.66       207\n",
            "weighted avg       0.74      0.75      0.73       207\n",
            "\n",
            "[[ 23  39]\n",
            " [ 12 133]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VCH10cwnAU-",
        "colab_type": "text"
      },
      "source": [
        "# Report: Write a summary of your approach to this problem; this should be like an abstract of a paper or the executive summary (you aim for clarity and passing on information, not going to details about known facts such as what decision trees are, assuming they are known to people in your research area).\n",
        "\n",
        "Must include statements such as:\n",
        "\n",
        "\n",
        "*   Include the problem definition: 1-2 lines\n",
        "*   Talk about train/val/test sets, size and how split.\n",
        "*   State what your test results are with the chosen method, parameters: e.g. \"We have obtained the best results with the ….. classifier (parameters=....) , giving classification accuracy of …% on test data….\"\n",
        "*   Comment on the speed of the algorithms and anything else that you deem important/interesting (e.g. confusion matrix)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72KDasqHnt1T",
        "colab_type": "text"
      },
      "source": [
        "# Write your report in this cell\n",
        "\n",
        "We are trying to classify if bank should give credit or not based on data about people's credit history and personal information about belongings. \n",
        "\n",
        "I splitted my 70% of data for training and 30% for validation and trained with decision tree and KNN classifiers.\n",
        "\n",
        "I have obtained the best results with the decision tree classifier *(parameters = {criterion: entropy, max_depth: 8, min_samples_split: 43})*, giving classification accuracy of **75.36232%** on test data.\n",
        "\n",
        "After training, decision tree was faster than the KNN, because KNN algorithm checks every data point to classify while decision tree only searchs 8 depth.\n",
        "\n",
        "Score about classification follows:\n",
        " \n",
        "            precision    recall  f1-score   support\n",
        "             0       0.66      0.37      0.47        62\n",
        "             1       0.77      0.92      0.84       145\n",
        "\n",
        "    accuracy                             0.75       207\n",
        "    macro avg        0.72      0.64      0.66       207\n",
        "    weighted avg     0.74      0.75      0.73       207\n",
        "\n",
        "Confusion matrix follows:\n",
        "\n",
        "    [ 23  39]\n",
        "    [ 12 133]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDDFZwSZbbwU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}